{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "npw9UvTRVibx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8jLo4NMVib8",
        "outputId": "02f4fae8-c1f0-4ac9-a3c7-fedd7c4810cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15957912.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_path = './'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpRWy-2hVib-",
        "outputId": "b14d74de-0ba7-48f2-e6ef-477c34dcd0ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(cifar10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUweptGVVicA",
        "outputId": "6062c2e6-af64-48b4-9cc0-d4ba1707473e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "isinstance(cifar10, torch.utils.data.Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AHh8DhIAVicA"
      },
      "outputs": [],
      "source": [
        "img, label = cifar10[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PU5UOOLVicB",
        "outputId": "300d69b7-546a-4cd8-92fa-7995712eb4ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cczHoI-jVicC"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xIoo96hhVicD"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8*8*8, 32)\n",
        "\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "\n",
        "        out = out.view(-1, 8*8*8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "heQkCw8YVicD"
      },
      "outputs": [],
      "source": [
        "def training_loop(n_epechs, optimizer, model, loss_fn, train_loader, val_loader):\n",
        "    for epoch in range(1, n_epechs + 1):\n",
        "        losses = 0.0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "\n",
        "            out = model(imgs)\n",
        "            loss = loss_fn(out, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses += loss.item()\n",
        "\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                imgs, labels = data\n",
        "                out = model(imgs)\n",
        "                _, pred = torch.max(out, 1)\n",
        "                c = (pred == labels).squeeze()\n",
        "                correct += c.sum()\n",
        "\n",
        "        print(epoch, losses/len(train_loader), correct/len(cifar10_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkUMRsEeVicE",
        "outputId": "6db5d515-6222-41e0-b1a7-3b310cb2220d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1.7789772721507666 tensor(0.4373)\n",
            "2 1.4481457519104413 tensor(0.5237)\n",
            "3 1.2913902085607925 tensor(0.4778)\n",
            "4 1.1990187265683927 tensor(0.5033)\n",
            "5 1.1391978399527958 tensor(0.5573)\n",
            "6 1.0939035244152675 tensor(0.5710)\n",
            "7 1.0573693354568823 tensor(0.6021)\n",
            "8 1.0257844892151826 tensor(0.5965)\n",
            "9 1.000690243661861 tensor(0.5112)\n",
            "10 0.9765799566912834 tensor(0.6036)\n",
            "11 0.9570879386666485 tensor(0.6224)\n",
            "12 0.9364162214729183 tensor(0.6337)\n",
            "13 0.9250510257223378 tensor(0.5574)\n",
            "14 0.9091725993491805 tensor(0.6296)\n",
            "15 0.8987151977351254 tensor(0.6074)\n",
            "16 0.8869173546581317 tensor(0.6406)\n",
            "17 0.873153803065 tensor(0.6293)\n",
            "18 0.8636263725550278 tensor(0.6374)\n",
            "19 0.8554771773498077 tensor(0.6450)\n",
            "20 0.8482040746894943 tensor(0.6471)\n",
            "21 0.8426987602735114 tensor(0.5827)\n",
            "22 0.8315050373296908 tensor(0.6232)\n",
            "23 0.8239210305540153 tensor(0.6348)\n",
            "24 0.8193803027538997 tensor(0.6330)\n",
            "25 0.812749119022923 tensor(0.6349)\n",
            "26 0.8096763923040131 tensor(0.6265)\n",
            "27 0.8005234063662532 tensor(0.6411)\n",
            "28 0.7940581065919393 tensor(0.6154)\n",
            "29 0.7924642191289941 tensor(0.6530)\n",
            "30 0.7835029035501773 tensor(0.6326)\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epechs=30,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QVjaRirHVicF"
      },
      "outputs": [],
      "source": [
        "f64 = ()\n",
        "with torch.no_grad():\n",
        "  for img, label in val_loader:\n",
        "    out = model(img)\n",
        "    f64 = (out, label)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, label = f64"
      ],
      "metadata": {
        "id": "1jeIHZ4IeZwY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.argmax(pred, 1).numpy()\n",
        "y = label.numpy()"
      ],
      "metadata": {
        "id": "w-Yh7DcXea18"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOkJJ9VUet1A",
        "outputId": "1e93a0c6-1bc4-4c7b-e7c3-d76e18c420a1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.50      0.43         6\n",
            "           1       0.78      0.88      0.82         8\n",
            "           2       0.29      0.33      0.31         6\n",
            "           3       0.80      0.36      0.50        11\n",
            "           4       0.50      0.67      0.57         3\n",
            "           5       0.60      0.75      0.67         8\n",
            "           6       0.67      0.67      0.67         3\n",
            "           7       0.86      0.86      0.86         7\n",
            "           8       1.00      0.50      0.67         6\n",
            "           9       0.50      0.67      0.57         6\n",
            "\n",
            "    accuracy                           0.61        64\n",
            "   macro avg       0.64      0.62      0.61        64\n",
            "weighted avg       0.66      0.61      0.61        64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ia278juqfCqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "usual",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}