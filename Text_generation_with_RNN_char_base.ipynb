{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EptnD6jIWVpF",
        "outputId": "4c358751-c2dd-47b2-8c5f-45cc5220ac4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-05 16:35:18--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.14’\n",
            "\n",
            "\rinput.txt.14          0%[                    ]       0  --.-KB/s               \rinput.txt.14        100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-05 16:35:18 (89.3 MB/s) - ‘input.txt.14’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1XEMk3RhSFZs"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Fygi7uqWWfVM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAYSj8A0WP2M",
        "outputId": "7dbe154a-1f09-4b6c-e388-b57daeee0c04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input.txt     input.txt.11  input.txt.14  input.txt.4  input.txt.7  sample_data\n",
            "input.txt.1   input.txt.12  input.txt.2   input.txt.5  input.txt.8\n",
            "input.txt.10  input.txt.13  input.txt.3   input.txt.6  input.txt.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "H6VgW_sOWZQW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('./input.txt', 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "id": "rQZAy1zOWeQp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fckXI8PQWz68",
        "outputId": "2954f68f-fc70-4b10-cb54-e8e3b7911f06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))"
      ],
      "metadata": {
        "id": "RS3Iqr12W1Li"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocab))\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o49sVXZ1XGi8",
        "outputId": "ea6d2ccc-f46a-481a-89bc-48fab590933b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = {i: id for id, i in enumerate(vocab)}\n",
        "chars_from_ids = {id: i for id, i in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "ppR_Gn67Xpdm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids_from_chars)\n",
        "print(chars_from_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMknDo5XYPJm",
        "outputId": "48dac7a6-2ba6-4e95-e14b-592e77e7ef94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  text = ''\n",
        "  for i in ids:\n",
        "    text += chars_from_ids[i]\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "BwblW4v4ZqOk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tensor(start):\n",
        "  chars = []\n",
        "  for char in start:\n",
        "    chars.append(ids_from_chars[char])\n",
        "\n",
        "  return torch.tensor([chars])"
      ],
      "metadata": {
        "id": "nve7Y9ZOV_yF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_tensor('hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odMoSfByWk30",
        "outputId": "21eb3826-a6ea-4abe-ed14-690df2efddc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[46, 47]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_from_ids([51, 53, 51, 1, 51, 53, 51])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "h4NXuMjfakGd",
        "outputId": "887ca1d5-d9cc-4a7a-f2e0-9810db7b599d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mom mom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = [ids_from_chars[i] for i in text]"
      ],
      "metadata": {
        "id": "vPRXF5Wfaykc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "sequences = []\n",
        "\n",
        "while (i <= len(all_ids) // 100):\n",
        "  sequences.append(all_ids[i:i + 101])\n",
        "  i+= 101\n",
        "\n",
        "sequences = torch.tensor(sequences)"
      ],
      "metadata": {
        "id": "nTXmR5Br3SdQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk0ChimIVLgV",
        "outputId": "cb57d317-5b88-44dc-c79f-26c085828899"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([111, 101])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDS(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, index):\n",
        "    X = self.data[index][:-1]\n",
        "    y = self.data[index][1:]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "m3nKE7r78W89"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ds = MyDS(sequences)"
      ],
      "metadata": {
        "id": "oHU-NVw1_U16"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(new_ds, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "cgaTo2oP_xPg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = next(iter(dl))"
      ],
      "metadata": {
        "id": "JhAo6GHgV2-E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_from_ids(X.numpy()[0]),text_from_ids(y.numpy()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24cbU_QlV-VK",
        "outputId": "b69f7bdd-7b4b-4865-c350-6b40fd55fd31"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('his country he did it to\\nplease his mother and to be partly proud; which he\\nis, even till the altitu',\n",
              " 'is country he did it to\\nplease his mother and to be partly proud; which he\\nis, even till the altitud')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF-UsFscBX8H",
        "outputId": "f7a86e86-fd78-4cff-e88f-012874506be4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 100]), torch.Size([32, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = nn.RNN(input_size=embedding_dim,\n",
        "                      hidden_size=hidden_size,\n",
        "                      num_layers=num_layers,\n",
        "                      batch_first=True)\n",
        "\n",
        "    self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "\n",
        "    # pdb.set_trace()\n",
        "    out = out.contiguous().view(-1, self.hidden_size)\n",
        "    out = self.fc1(out)\n",
        "\n",
        "    return out, hidden\n",
        "  def init_hidden(self, batch_size):\n",
        "    return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n"
      ],
      "metadata": {
        "id": "8n812nnSuaU1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, dataloader, num_epochs, optimizer, loss_fn):\n",
        "  losses = []\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    for X, y in dataloader:\n",
        "\n",
        "      y_hat, hidden = model(X)\n",
        "\n",
        "      loss = loss_fn(y_hat, y.view(-1).long())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(epoch, num_epochs, float(loss))\n"
      ],
      "metadata": {
        "id": "R_Qi6QGB0tzY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "num_layers = 4"
      ],
      "metadata": {
        "id": "ggoryWwrW_ed"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_size=256, num_layers=num_layers)"
      ],
      "metadata": {
        "id": "dbKMV-8V3BOD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "b21qH0tz7I8d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(model, dataloader=dl, num_epochs=100, optimizer=optimizer, loss_fn=loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1obnpKC678_",
        "outputId": "8765773f-eaa1-43aa-8c1d-5e25110629ee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 100 2.1780879497528076\n",
            "20 100 1.7825469970703125\n",
            "30 100 1.3815561532974243\n",
            "40 100 1.0399137735366821\n",
            "50 100 0.6719143986701965\n",
            "60 100 0.5063482522964478\n",
            "70 100 0.29081135988235474\n",
            "80 100 0.1873340904712677\n",
            "90 100 0.1123259887099266\n",
            "100 100 0.10883636772632599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.tensor([[21, 22]])\n",
        "  out, hidden = model(x)\n",
        "\n",
        "  print(out.shape)\n",
        "  print(chars_from_ids[int(torch.argmax(out[-1,:]).item())])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4g6FKkB7ydL",
        "outputId": "9c26a935-5299-4d11-c4cf-2adf8f2ad021"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 65])\n",
            "-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, tensor):\n",
        "  out, hidden = model(tensor)\n",
        "  ids = int(torch.argmax(out[-1, :]).item())\n",
        "  return ids"
      ],
      "metadata": {
        "id": "F-nuhZd81IK4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, size, start):\n",
        "  model.eval()\n",
        "\n",
        "  sentence = text_to_tensor(start).tolist()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    len_to_predict = size - len(sentence[0])\n",
        "\n",
        "    for i in range(len_to_predict):\n",
        "      pred_char = predict(model, torch.tensor(sentence))\n",
        "      sentence[0].append(pred_char)\n",
        "\n",
        "  return text_from_ids(sentence[0])"
      ],
      "metadata": {
        "id": "bbbM7asKVi6_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model, 1000, 'MENENIUS:'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgwFghs3YYVp",
        "outputId": "d9b4b958-00c5-4769-943d-db029259a0ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MENENIUS:\n",
            "For corn at their own rates; where go you\n",
            "With bats and clubs:\n",
            "Rome and her rats are at the point of battle;\n",
            "The one side must have a lest were so!\n",
            "\n",
            "MENENIUS:\n",
            "What work's, my countrymen, in him. You must\n",
            "Confess you lions, finds you hares;\n",
            "Where foxes, geese: you are no surer, noble Marcius!\n",
            "\n",
            "MARCIUS:\n",
            "First unroof'd the city,\n",
            "Ere so prevail'd with me: with these shreds\n",
            "They'll sit by the fire, and presume to know\n",
            "What's done i' the Capitol!\n",
            "\n",
            "All:\n",
            "Come, come.\n",
            "\n",
            "First Citizen:\n",
            "Ye're long about it.\n",
            "\n",
            "MENENIUS:\n",
            "Note me this, good friend;\n",
            "Your most grave belly was now your hate,\n",
            "Him vile that hath always loved\n",
            "the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Ye're long about it.\n",
            "\n",
            "MENENIUS:\n",
            "Note me this, good friend;\n",
            "Your most grave belly was now your hate,\n",
            "Him vile that hath always loved\n",
            "the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Ye're long about it.\n",
            "\n",
            "MENENIUS:\n",
            "Note me this, good friend;\n",
            "Your most grave belly was now your hate,\n",
            "Him vile that hath always loved\n",
            "the\n"
          ]
        }
      ]
    }
  ]
}